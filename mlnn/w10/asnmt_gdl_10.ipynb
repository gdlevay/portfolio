{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks image recognition - MultiLayer Perceptron\n",
    "Use both MLNN for the following problem.\n",
    "\n",
    "1. Add random noise (see below on `size parameter` on [`np.random.normal`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html)) to the images in training and testing. **Make sure each image gets a different noise feature added to it. Inspect by printing out several images. Note - the `size` parameter should match the data. **\n",
    "2. Compare the `accuracy` of train and val after N epochs for MLNN with and without noise. \n",
    "3. Vary the amount of noise by changing the `scale` parameter in `np.random.normal` by a factor. Use `.1, .5, 1.0, 2.0, 4.0` for the `scale` and keep track of the `accuracy` for training and validation and plot these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `np.random.normal`\n",
    "\n",
    "## Parameters\n",
    "\n",
    "### loc\n",
    "\n",
    "Mean (“centre”) of the distribution.\n",
    "\n",
    "### scale\n",
    "\n",
    "Standard deviation (spread or “width”) of the distribution. Must be non-negative.\n",
    "\n",
    "### size\n",
    "\n",
    "Output shape. If the given shape is, e.g., (m, n, k), then m * n * k samples are drawn. If size is None (default), a single value is returned if loc and scale are both scalars. Otherwise, np.broadcast(loc, scale).size samples are drawn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - Image Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Neural Network\n",
    "Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise(data, scale = 0.1):\n",
    "    new_data = data + np.random.normal(0, scale, (784,))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(x_train, x_test, y_train, y_test, scale = 0):\n",
    "    batch_size = 128\n",
    "    num_classes = 10\n",
    "    epochs = 20\n",
    "\n",
    "    \n",
    "    x_train = x_train.copy()\n",
    "    x_test = x_test.copy()\n",
    "    \n",
    "    x_train = generate_noise(x_train, scale)\n",
    "    x_test = generate_noise(x_test, scale)\n",
    "    \n",
    "    plt.imshow(x_train[12].reshape(28,28))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=RMSprop(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    return[\n",
    "        history, score\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 7s 12ms/step - loss: 0.2456 - accuracy: 0.9253 - val_loss: 0.1156 - val_accuracy: 0.9659\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.1035 - accuracy: 0.9686 - val_loss: 0.0764 - val_accuracy: 0.9761\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0734 - accuracy: 0.9780 - val_loss: 0.0904 - val_accuracy: 0.9749\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0593 - accuracy: 0.9823 - val_loss: 0.0678 - val_accuracy: 0.9821\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0512 - accuracy: 0.9843 - val_loss: 0.0700 - val_accuracy: 0.9818\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0435 - accuracy: 0.9871 - val_loss: 0.0767 - val_accuracy: 0.9805\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0375 - accuracy: 0.9884 - val_loss: 0.0808 - val_accuracy: 0.9819\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0332 - accuracy: 0.9901 - val_loss: 0.0864 - val_accuracy: 0.9824\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0310 - accuracy: 0.9909 - val_loss: 0.0866 - val_accuracy: 0.9815\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0289 - accuracy: 0.9917 - val_loss: 0.0881 - val_accuracy: 0.9834\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0277 - accuracy: 0.9919 - val_loss: 0.1001 - val_accuracy: 0.9840\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0234 - accuracy: 0.9934 - val_loss: 0.0988 - val_accuracy: 0.9822\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0225 - accuracy: 0.9934 - val_loss: 0.1009 - val_accuracy: 0.9828\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0224 - accuracy: 0.9936 - val_loss: 0.1071 - val_accuracy: 0.9802\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0196 - accuracy: 0.9944 - val_loss: 0.1179 - val_accuracy: 0.9812\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0201 - accuracy: 0.9944 - val_loss: 0.1114 - val_accuracy: 0.9835\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 7s 16ms/step - loss: 0.0191 - accuracy: 0.9953 - val_loss: 0.1122 - val_accuracy: 0.9825\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0169 - accuracy: 0.9954 - val_loss: 0.1393 - val_accuracy: 0.9830\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 6s 13ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 0.1504 - val_accuracy: 0.9815\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 8s 17ms/step - loss: 0.0176 - accuracy: 0.9952 - val_loss: 0.1381 - val_accuracy: 0.9824\n",
      "Test loss: 0.13811901211738586\n",
      "Test accuracy: 0.9824000000953674\n"
     ]
    }
   ],
   "source": [
    "history, score, scale = run_model(x_train, x_test, y_train, y_test, scale = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historys = []\n",
    "scores = []\n",
    "scales = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "397cdfd7b61b27e41d803842007fd6d369d02c3875755cf92521d65d265bcc16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
