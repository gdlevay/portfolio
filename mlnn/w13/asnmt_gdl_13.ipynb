{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP\n",
    "Find your favorite news source and grab the article text.\n",
    "\n",
    "1. Show the most common words in the article.\n",
    "2. Show the most common words under a part of speech. (i.e. NOUN: {'Bob':12, 'Alice':4,})\n",
    "3. Find a subject/object relationship through the dependency parser in any sentence.\n",
    "4. Show the most common Entities and their types. \n",
    "5. Find Entites and their dependency (hint: entity.root.head)\n",
    "6. Find the most similar words in the article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note: Yes, the notebook from the video is not provided, I leave it to you to make your own :) it's your final assignment for the semester. Enjoy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import smartquote\n",
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorital on how to webscrape an article\n",
    "1. Send Request\n",
    " - Requests is a library used by your command line which basically points your computer to that specific URL.\n",
    "    Everytime you click on a website in the browser, your computer is sending a 'request' to the URL\n",
    "    It is a request because if you don't have permission to view that URL, you will not be allowed to.\n",
    "- Note: you want to keep requests in a separate block and only re run it when absolutely necessary, this\n",
    "    is because you could potentially overload servers and most sites have an automatic IP block if your\n",
    "    requests exceed a certain number of requests/min.\n",
    "2. Parse it using BeautifulSoup\n",
    " - After sending your request you want to parse it using BeautifulSoups 'html.parser', \n",
    "\n",
    "3. Find specific element\n",
    " - soup.find is the command you use to find the specific HTML element you are looking for\n",
    " .text is needed because you don't want all the '<div class = ...>' stuff\n",
    " - For this specific example, on this website right click the article where it says \"DOHA Quarta\" and click 'Inspect'\n",
    "Keep scrolling to the top of your Elements window until you mouse over the element that contains all the content\n",
    "In this case the class is 'story-content', keep in mind this piece is trial and error and may take some time figuring\n",
    "out whether you have the right element or not\n",
    "working with articles, most times the class is something like [story, content, article, article-content]\n",
    "\n",
    "4. Clean text\n",
    " - Steps I performed here\n",
    "   1. Get rid of all of the text preceding and proceding the article\n",
    "   2. Get rid of all of the advertisements or photo captions within the article\n",
    "   3. Subsittute smartquotes for normal quotes\n",
    "    - Smart quotes are explained here https://en.wikipedia.org/wiki/Quotation_marks_in_English#Smart_quotes,\n",
    "    I believe this is only a problem for windows, but not sure. This step is necessary, otherwise you will run into\n",
    "    alot of problems later on\n",
    "   4. Replace \".word\" followed by words with \". word\", this will help because often SPACY depends on spaces in between words to distinguish them\n",
    "   5. Replace any double, triple, etc. spaces by a single space\n",
    "5. (optional) write to text file or CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = \"https://www.foxsports.com/stories/soccer/christian-pulisic-scores-biggest-usa-goal-in-12-years-as-u-s-advances\"\n",
    "res = requests.get(site)\n",
    "soup = BeautifulSoup(res.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = soup.find(class_ = 'story-content').text\n",
    "\n",
    "article = re.findall('DOHA, Qatar.+pain of failure.', content)[0]\n",
    "article = re.sub('Deandre Yedlin .+ \\(Photo by Claudio Villa/Getty Images\\)', '', article)\n",
    "article = re.sub('USA\\'s .+ in 38\\'', '', article)\n",
    "article = smartquote.substitute(article)\n",
    "article = re.sub('\\.(?=\\w)', '. ', article)\n",
    "article = re.sub('\\s+', ' ', article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"article.txt\", \"w\") as text_file:\n",
    "    text_file.write(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Show the most common words in the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(article)\n",
    "tokens = [token for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_text = [token.text for token in tokens\n",
    "          if not token.is_punct\n",
    "          and not token.is_stop\n",
    "          and not token.is_digit\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.Series(tokens_text).value_counts(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iran         9\n",
       "goal         7\n",
       "face         5\n",
       "Pulisic      5\n",
       "ball         5\n",
       "Americans    4\n",
       "game         4\n",
       "winning      3\n",
       "team         3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Show the most common words under a part of speech. (i.e. NOUN: {'Bob':12, 'Alice':4,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Bob', 'Noun')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [('Bob','Noun'), ('Alice','Noun'), ('Ran', 'Verb')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list.count() takes exactly one argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gdlev\\portfolio\\mlnn\\w13\\asnmt_gdl_13.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gdlev/portfolio/mlnn/w13/asnmt_gdl_13.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m l\u001b[39m.\u001b[39;49mcount()\n",
      "\u001b[1;31mTypeError\u001b[0m: list.count() takes exactly one argument (0 given)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_pos = [token.pos_ for token in tokens\n",
    "          if not token.is_punct\n",
    "          and not token.is_stop\n",
    "          and not token.is_digit\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_df = pd.DataFrame(zip(tokens_text, tokens_pos), columns = ['word', 'pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos    word         \n",
      "ADJ    American         2\n",
      "       defensive        2\n",
      "       free             2\n",
      "       abdominal        1\n",
      "       better           1\n",
      "       busier           1\n",
      "       calm             1\n",
      "       cautious         1\n",
      "       different        1\n",
      "       emotional        1\n",
      "       excellent        1\n",
      "       fierce           1\n",
      "       final            1\n",
      "       finer            1\n",
      "       heroic           1\n",
      "       important        1\n",
      "       little           1\n",
      "       lively           1\n",
      "       national         1\n",
      "       new              1\n",
      "       old              1\n",
      "       past             1\n",
      "       political        1\n",
      "       potential        1\n",
      "       ready            1\n",
      "       rife             1\n",
      "       set              1\n",
      "       sizable          1\n",
      "       speedy           1\n",
      "       total            1\n",
      "       ultra            1\n",
      "       unflinching      1\n",
      "       unmarked         1\n",
      "       winded           1\n",
      "       wracking         1\n",
      "       young            1\n",
      "ADP    alongside        1\n",
      "ADV    forward          2\n",
      "       longer           2\n",
      "       Earlier          1\n",
      "       Late             1\n",
      "       Suddenly         1\n",
      "       barely           1\n",
      "       exclusively      1\n",
      "       forever          1\n",
      "       forwards         1\n",
      "       gradually        1\n",
      "       heavily          1\n",
      "       home             1\n",
      "       ill              1\n",
      "       immediately      1\n",
      "       near             1\n",
      "       offside          1\n",
      "       presumably       1\n",
      "       right            1\n",
      "       seemingly        1\n",
      "       wide             1\n",
      "NOUN   goal             7\n",
      "       ball             5\n",
      "       face             5\n",
      "       game             4\n",
      "       break            3\n",
      "       minutes          3\n",
      "       team             3\n",
      "       bar              2\n",
      "       failure          2\n",
      "       half             2\n",
      "       midfield         2\n",
      "       moments          2\n",
      "       need             2\n",
      "       pain             2\n",
      "       price            2\n",
      "       time             2\n",
      "       way              2\n",
      "       yards            2\n",
      "       action           1\n",
      "       anthem           1\n",
      "       area             1\n",
      "       bench            1\n",
      "       body             1\n",
      "       boost            1\n",
      "       boot             1\n",
      "       box              1\n",
      "       breakaways       1\n",
      "       buildup          1\n",
      "       care             1\n",
      "       chances          1\n",
      "       chest            1\n",
      "       clash            1\n",
      "       coach            1\n",
      "       contest          1\n",
      "       country          1\n",
      "       crunch           1\n",
      "       days             1\n",
      "       dedication       1\n",
      "       defender         1\n",
      "       defense          1\n",
      "       defiance         1\n",
      "       deficiency       1\n",
      "       devil            1\n",
      "       effectiveness    1\n",
      "       elimination      1\n",
      "       emotion          1\n",
      "       end              1\n",
      "       equalizing       1\n",
      "       equation         1\n",
      "       fans             1\n",
      "       figurehead       1\n",
      "       flag             1\n",
      "       flank            1\n",
      "       folly            1\n",
      "       foot             1\n",
      "       frustration      1\n",
      "       gain             1\n",
      "       goalkeeper       1\n",
      "       goals            1\n",
      "       halftime         1\n",
      "       hand             1\n",
      "       head             1\n",
      "       header           1\n",
      "       history          1\n",
      "       hospital         1\n",
      "       injury           1\n",
      "       ins              1\n",
      "       kick             1\n",
      "       kicks            1\n",
      "       knockout         1\n",
      "       lead             1\n",
      "       line             1\n",
      "       man              1\n",
      "       matchup          1\n",
      "       men              1\n",
      "       nerve            1\n",
      "       net              1\n",
      "       night            1\n",
      "       onslaught        1\n",
      "       option           1\n",
      "       pair             1\n",
      "       pass             1\n",
      "       pieces           1\n",
      "       players          1\n",
      "       possession       1\n",
      "       pre              1\n",
      "       pressure         1\n",
      "       priorities       1\n",
      "       race             1\n",
      "       reach            1\n",
      "       resolve          1\n",
      "       role             1\n",
      "       round            1\n",
      "       rounds           1\n",
      "       scans            1\n",
      "       shin             1\n",
      "       shot             1\n",
      "       shoulder         1\n",
      "       spirit           1\n",
      "       stage            1\n",
      "       striker          1\n",
      "       superstar        1\n",
      "       surprise         1\n",
      "       tactics          1\n",
      "       talk             1\n",
      "       task             1\n",
      "       teams            1\n",
      "       teen             1\n",
      "       threat           1\n",
      "       throw            1\n",
      "       tournament       1\n",
      "       turf             1\n",
      "       underdog         1\n",
      "       undertones       1\n",
      "       wall             1\n",
      "       win              1\n",
      "       winner           1\n",
      "       year             1\n",
      "       years            1\n",
      "PROPN  Iran             9\n",
      "       Pulisic          5\n",
      "       Americans        4\n",
      "       Dest             3\n",
      "       Taremi           3\n",
      "       Turner           3\n",
      "       Berhalter        2\n",
      "       Carter           2\n",
      "       Ghoddos          2\n",
      "       McKennie         2\n",
      "       Mehdi            2\n",
      "       USA              2\n",
      "       Vickers          2\n",
      "       Weah             2\n",
      "       Zimmerman        2\n",
      "       Aaronson         1\n",
      "       Al               1\n",
      "       Alireza          1\n",
      "       American         1\n",
      "       Azmoun           1\n",
      "       Beiranvand       1\n",
      "       Brenden          1\n",
      "       Cameron          1\n",
      "       Carlos           1\n",
      "       Champions        1\n",
      "       Chelsea          1\n",
      "       Christian        1\n",
      "       Cup              1\n",
      "       DOHA             1\n",
      "       England          1\n",
      "       Gregg            1\n",
      "       Josh             1\n",
      "       League           1\n",
      "       Matt             1\n",
      "       Morteza          1\n",
      "       Netherlands      1\n",
      "       Pouraliganji     1\n",
      "       Qatar            1\n",
      "       Queiroz          1\n",
      "       Ream             1\n",
      "       Saman            1\n",
      "       Sardar           1\n",
      "       Sargent          1\n",
      "       Saturday         1\n",
      "       Sergi√±o          1\n",
      "       Stadium          1\n",
      "       States           1\n",
      "       Thumama          1\n",
      "       Tim              1\n",
      "       Timothy          1\n",
      "       Tuesday          1\n",
      "       United           1\n",
      "       Walker           1\n",
      "       Weston           1\n",
      "       World            1\n",
      "       paramount        1\n",
      "       squad            1\n",
      "SCONJ  despite          2\n",
      "VERB   winning          3\n",
      "       \"Onward          1\n",
      "       advanced         1\n",
      "       advised          1\n",
      "       announced        1\n",
      "       beat             1\n",
      "       belted           1\n",
      "       broke            1\n",
      "       brought          1\n",
      "       changed          1\n",
      "       collected        1\n",
      "       collided         1\n",
      "       commanding       1\n",
      "       connect          1\n",
      "       consider         1\n",
      "       contorted        1\n",
      "       creating         1\n",
      "       curled           1\n",
      "       decided          1\n",
      "       destined         1\n",
      "       emerge           1\n",
      "       etched           1\n",
      "       failed           1\n",
      "       fell             1\n",
      "       floated          1\n",
      "       gained           1\n",
      "       got              1\n",
      "       headed           1\n",
      "       hold             1\n",
      "       introducing      1\n",
      "       know             1\n",
      "       knowing          1\n",
      "       lay              1\n",
      "       liked            1\n",
      "       lost             1\n",
      "       march            1\n",
      "       muscling         1\n",
      "       nearing          1\n",
      "       needed           1\n",
      "       needs            1\n",
      "       nodded           1\n",
      "       paid             1\n",
      "       play             1\n",
      "       pounce           1\n",
      "       prepared         1\n",
      "       pressed          1\n",
      "       prevent          1\n",
      "       proven           1\n",
      "       received         1\n",
      "       relegating       1\n",
      "       replaced         1\n",
      "       required         1\n",
      "       rubbed           1\n",
      "       ruled            1\n",
      "       saw              1\n",
      "       score            1\n",
      "       scored           1\n",
      "       scoring          1\n",
      "       secure           1\n",
      "       seeing           1\n",
      "       showed           1\n",
      "       sit              1\n",
      "       sitting          1\n",
      "       sought           1\n",
      "       speeding         1\n",
      "       spotted          1\n",
      "       sprung           1\n",
      "       steer            1\n",
      "       steered          1\n",
      "       struggled        1\n",
      "       surviving        1\n",
      "       taken            1\n",
      "       taking           1\n",
      "       took             1\n",
      "       underestimate    1\n",
      "       whipped          1\n",
      "       won              1\n",
      "       write            1\n",
      "Name: word, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None\n",
    "                       ):\n",
    "    print(tokens_df.groupby(by='pos')['word'].value_counts(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "397cdfd7b61b27e41d803842007fd6d369d02c3875755cf92521d65d265bcc16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
